{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "9-2-3_eco.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eBwicKA0lwH",
        "colab_type": "text"
      },
      "source": [
        "# ECOモデルの実装\n",
        "本ファイルでは、ECOモデルを実装します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyb6wnqP0uEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceefd663-a1cb-4ba3-f7d8-bf9d16b35d4e"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEApgRfo0oWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8176c68f-3d3e-402a-de97-7027022093c9"
      },
      "source": [
        "!git clone https://github.com/HisakaKoji/pytorch_advanced.git"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_advanced'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/52)\u001b[K\rremote: Counting objects:   3% (2/52)\u001b[K\rremote: Counting objects:   5% (3/52)\u001b[K\rremote: Counting objects:   7% (4/52)\u001b[K\rremote: Counting objects:   9% (5/52)\u001b[K\rremote: Counting objects:  11% (6/52)\u001b[K\rremote: Counting objects:  13% (7/52)\u001b[K\rremote: Counting objects:  15% (8/52)\u001b[K\rremote: Counting objects:  17% (9/52)\u001b[K\rremote: Counting objects:  19% (10/52)\u001b[K\rremote: Counting objects:  21% (11/52)\u001b[K\rremote: Counting objects:  23% (12/52)\u001b[K\rremote: Counting objects:  25% (13/52)\u001b[K\rremote: Counting objects:  26% (14/52)\u001b[K\rremote: Counting objects:  28% (15/52)\u001b[K\rremote: Counting objects:  30% (16/52)\u001b[K\rremote: Counting objects:  32% (17/52)\u001b[K\rremote: Counting objects:  34% (18/52)\u001b[K\rremote: Counting objects:  36% (19/52)\u001b[K\rremote: Counting objects:  38% (20/52)\u001b[K\rremote: Counting objects:  40% (21/52)\u001b[K\rremote: Counting objects:  42% (22/52)\u001b[K\rremote: Counting objects:  44% (23/52)\u001b[K\rremote: Counting objects:  46% (24/52)\u001b[K\rremote: Counting objects:  48% (25/52)\u001b[K\rremote: Counting objects:  50% (26/52)\u001b[K\rremote: Counting objects:  51% (27/52)\u001b[K\rremote: Counting objects:  53% (28/52)\u001b[K\rremote: Counting objects:  55% (29/52)\u001b[K\rremote: Counting objects:  57% (30/52)\u001b[K\rremote: Counting objects:  59% (31/52)\u001b[K\rremote: Counting objects:  61% (32/52)\u001b[K\rremote: Counting objects:  63% (33/52)\u001b[K\rremote: Counting objects:  65% (34/52)\u001b[K\rremote: Counting objects:  67% (35/52)\u001b[K\rremote: Counting objects:  69% (36/52)\u001b[K\rremote: Counting objects:  71% (37/52)\u001b[K\rremote: Counting objects:  73% (38/52)\u001b[K\rremote: Counting objects:  75% (39/52)\u001b[K\rremote: Counting objects:  76% (40/52)\u001b[K\rremote: Counting objects:  78% (41/52)\u001b[K\rremote: Counting objects:  80% (42/52)\u001b[K\rremote: Counting objects:  82% (43/52)\u001b[K\rremote: Counting objects:  84% (44/52)\u001b[K\rremote: Counting objects:  86% (45/52)\u001b[K\rremote: Counting objects:  88% (46/52)\u001b[K\rremote: Counting objects:  90% (47/52)\u001b[K\rremote: Counting objects:  92% (48/52)\u001b[K\rremote: Counting objects:  94% (49/52)\u001b[K\rremote: Counting objects:  96% (50/52)\u001b[K\rremote: Counting objects:  98% (51/52)\u001b[K\rremote: Counting objects: 100% (52/52)\u001b[K\rremote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 495 (delta 26), reused 0 (delta 0), pack-reused 443\n",
            "Receiving objects: 100% (495/495), 18.01 MiB | 38.26 MiB/s, done.\n",
            "Resolving deltas: 100% (261/261), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAmnsnEV0rph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8273176c-9af8-4db3-f28b-82ab59e55a5a"
      },
      "source": [
        "%cd  pytorch_advanced/9_video_classification_eco/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch_advanced/9_video_classification_eco\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8zVv6vr0lwJ",
        "colab_type": "text"
      },
      "source": [
        "# 9.2 学習目標\n",
        "\n",
        "1.\tECOの2D Netモジュールの概要を理解する\n",
        "2.\tInception-v2を実装できるようになる\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvDiRJmZ0lwL",
        "colab_type": "text"
      },
      "source": [
        "# 9.3 学習目標\n",
        "\n",
        "1.\tECOの3D Netモジュールの概要を理解する\n",
        "2.\t3D Resnetを実装できるようになる\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33f2bDJV0lwM",
        "colab_type": "text"
      },
      "source": [
        "# 事前準備\n",
        "\n",
        "とくになし"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQl8U0KE0lwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUeFvhd50lwV",
        "colab_type": "text"
      },
      "source": [
        "# ECOの2D Netモジュール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCxH89VO0lwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicConv(nn.Module):\n",
        "    '''ECOの2D Netモジュールの最初のモジュール'''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BasicConv, self).__init__()\n",
        "\n",
        "        self.conv1_7x7_s2 = nn.Conv2d(3, 64, kernel_size=(\n",
        "            7, 7), stride=(2, 2), padding=(3, 3))\n",
        "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv1_relu_7x7 = nn.ReLU(inplace=True)\n",
        "        self.pool1_3x3_s2 = nn.MaxPool2d(\n",
        "            kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
        "        self.conv2_3x3_reduce = nn.Conv2d(\n",
        "            64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.conv2_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_relu_3x3_reduce = nn.ReLU(inplace=True)\n",
        "        self.conv2_3x3 = nn.Conv2d(64, 192, kernel_size=(\n",
        "            3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv2_3x3_bn = nn.BatchNorm2d(\n",
        "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_relu_3x3 = nn.ReLU(inplace=True)\n",
        "        self.pool2_3x3_s2 = nn.MaxPool2d(\n",
        "            kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1_7x7_s2(x)\n",
        "        out = self.conv1_7x7_s2_bn(out)\n",
        "        out = self.conv1_relu_7x7(out)\n",
        "        out = self.pool1_3x3_s2(out)\n",
        "        out = self.conv2_3x3_reduce(out)\n",
        "        out = self.conv2_3x3_reduce_bn(out)\n",
        "        out = self.conv2_relu_3x3_reduce(out)\n",
        "        out = self.conv2_3x3(out)\n",
        "        out = self.conv2_3x3_bn(out)\n",
        "        out = self.conv2_relu_3x3(out)\n",
        "        out = self.pool2_3x3_s2(out)\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm6Od9tX0lwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionA(nn.Module):\n",
        "    '''InceptionA'''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(InceptionA, self).__init__()\n",
        "\n",
        "        self.inception_3a_1x1 = nn.Conv2d(\n",
        "            192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_1x1_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_1x1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3a_3x3_reduce = nn.Conv2d(\n",
        "            192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_3x3_reduce = nn.ReLU(inplace=True)\n",
        "        self.inception_3a_3x3 = nn.Conv2d(\n",
        "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_3x3_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_3x3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3a_double_3x3_reduce = nn.Conv2d(\n",
        "            192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_double_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_double_3x3_reduce = nn.ReLU(inplace=True)\n",
        "        self.inception_3a_double_3x3_1 = nn.Conv2d(\n",
        "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_double_3x3_1_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_double_3x3_1 = nn.ReLU(inplace=True)\n",
        "        self.inception_3a_double_3x3_2 = nn.Conv2d(\n",
        "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_double_3x3_2_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_double_3x3_2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3a_pool = nn.AvgPool2d(\n",
        "            kernel_size=3, stride=1, padding=1)\n",
        "        self.inception_3a_pool_proj = nn.Conv2d(\n",
        "            192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_pool_proj_bn = nn.BatchNorm2d(\n",
        "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_pool_proj = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out1 = self.inception_3a_1x1(x)\n",
        "        out1 = self.inception_3a_1x1_bn(out1)\n",
        "        out1 = self.inception_3a_relu_1x1(out1)\n",
        "\n",
        "        out2 = self.inception_3a_3x3_reduce(x)\n",
        "        out2 = self.inception_3a_3x3_reduce_bn(out2)\n",
        "        out2 = self.inception_3a_relu_3x3_reduce(out2)\n",
        "        out2 = self.inception_3a_3x3(out2)\n",
        "        out2 = self.inception_3a_3x3_bn(out2)\n",
        "        out2 = self.inception_3a_relu_3x3(out2)\n",
        "\n",
        "        out3 = self.inception_3a_double_3x3_reduce(x)\n",
        "        out3 = self.inception_3a_double_3x3_reduce_bn(out3)\n",
        "        out3 = self.inception_3a_relu_double_3x3_reduce(out3)\n",
        "        out3 = self.inception_3a_double_3x3_1(out3)\n",
        "        out3 = self.inception_3a_double_3x3_1_bn(out3)\n",
        "        out3 = self.inception_3a_relu_double_3x3_1(out3)\n",
        "        out3 = self.inception_3a_double_3x3_2(out3)\n",
        "        out3 = self.inception_3a_double_3x3_2_bn(out3)\n",
        "        out3 = self.inception_3a_relu_double_3x3_2(out3)\n",
        "\n",
        "        out4 = self.inception_3a_pool(x)\n",
        "        out4 = self.inception_3a_pool_proj(out4)\n",
        "        out4 = self.inception_3a_pool_proj_bn(out4)\n",
        "        out4 = self.inception_3a_relu_pool_proj(out4)\n",
        "\n",
        "        outputs = [out1, out2, out3, out4]\n",
        "\n",
        "        return torch.cat(outputs, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiRDZB_E0lwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionB(nn.Module):\n",
        "    '''InceptionB'''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(InceptionB, self).__init__()\n",
        "        \n",
        "        self.inception_3b_1x1 = nn.Conv2d(\n",
        "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_1x1_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_1x1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3b_3x3_reduce = nn.Conv2d(\n",
        "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_3x3_reduce = nn.ReLU(inplace=True)\n",
        "        self.inception_3b_3x3 = nn.Conv2d(\n",
        "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_3x3_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_3x3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3b_double_3x3_reduce = nn.Conv2d(\n",
        "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_double_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_double_3x3_reduce = nn.ReLU(inplace=True)\n",
        "        self.inception_3b_double_3x3_1 = nn.Conv2d(\n",
        "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_double_3x3_1_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_double_3x3_1 = nn.ReLU(inplace=True)\n",
        "        self.inception_3b_double_3x3_2 = nn.Conv2d(\n",
        "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_double_3x3_2_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_double_3x3_2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3b_pool = nn.AvgPool2d(\n",
        "            kernel_size=3, stride=1, padding=1)\n",
        "        self.inception_3b_pool_proj = nn.Conv2d(\n",
        "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_pool_proj_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_pool_proj = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        out1 = self.inception_3b_1x1(x)\n",
        "        out1 = self.inception_3b_1x1_bn(out1)\n",
        "        out1 = self.inception_3b_relu_1x1(out1)\n",
        "\n",
        "        out2 = self.inception_3b_3x3_reduce(x)\n",
        "        out2 = self.inception_3b_3x3_reduce_bn(out2)\n",
        "        out2 = self.inception_3b_relu_3x3_reduce(out2)\n",
        "        out2 = self.inception_3b_3x3(out2)\n",
        "        out2 = self.inception_3b_3x3_bn(out2)\n",
        "        out2 = self.inception_3b_relu_3x3(out2)\n",
        "\n",
        "        out3 = self.inception_3b_double_3x3_reduce(x)\n",
        "        out3 = self.inception_3b_double_3x3_reduce_bn(out3)\n",
        "        out3 = self.inception_3b_relu_double_3x3_reduce(out3)\n",
        "        out3 = self.inception_3b_double_3x3_1(out3)\n",
        "        out3 = self.inception_3b_double_3x3_1_bn(out3)\n",
        "        out3 = self.inception_3b_relu_double_3x3_1(out3)\n",
        "        out3 = self.inception_3b_double_3x3_2(out3)\n",
        "        out3 = self.inception_3b_double_3x3_2_bn(out3)\n",
        "        out3 = self.inception_3b_relu_double_3x3_2(out3)\n",
        "\n",
        "        out4 = self.inception_3b_pool(x)\n",
        "        out4 = self.inception_3b_pool_proj(out4)\n",
        "        out4 = self.inception_3b_pool_proj_bn(out4)\n",
        "        out4 = self.inception_3b_relu_pool_proj(out4)\n",
        "\n",
        "        outputs = [out1, out2, out3, out4]\n",
        "\n",
        "        return torch.cat(outputs, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLzmRIOM0lwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionC(nn.Module):\n",
        "    '''InceptionC'''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(InceptionC, self).__init__()\n",
        "\n",
        "        self.inception_3c_double_3x3_reduce = nn.Conv2d(\n",
        "            320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3c_double_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3c_relu_double_3x3_reduce = nn.ReLU(inplace=True)\n",
        "        self.inception_3c_double_3x3_1 = nn.Conv2d(\n",
        "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3c_double_3x3_1_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3c_relu_double_3x3_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.inception_3c_double_3x3_reduce(x)\n",
        "        out = self.inception_3c_double_3x3_reduce_bn(out)\n",
        "        out = self.inception_3c_relu_double_3x3_reduce(out)\n",
        "        out = self.inception_3c_double_3x3_1(out)\n",
        "        out = self.inception_3c_double_3x3_1_bn(out)\n",
        "        out = self.inception_3c_relu_double_3x3_1(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyNP4DQi0lwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ECO_2D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ECO_2D, self).__init__()\n",
        "\n",
        "        # BasicConvモジュール\n",
        "        self.basic_conv = BasicConv()\n",
        "\n",
        "        # Inceptionモジュール\n",
        "        self.inception_a = InceptionA()\n",
        "        self.inception_b = InceptionB()\n",
        "        self.inception_c = InceptionC()\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        入力xのサイズtorch.Size([batch_num, 3, 224, 224]))\n",
        "        '''\n",
        "        out = self.basic_conv(x)\n",
        "        out = self.inception_a(out)\n",
        "        out = self.inception_b(out)\n",
        "        out = self.inception_c(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mhzbT3_0lwu",
        "colab_type": "text"
      },
      "source": [
        "## 動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LosrLkLQ0lwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89547c19-013d-4a6a-fb84-a5c216d72593"
      },
      "source": [
        "# モデルの用意\n",
        "net = ECO_2D()\n",
        "net.train()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ECO_2D(\n",
              "  (basic_conv): BasicConv(\n",
              "    (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv1_relu_7x7): ReLU(inplace=True)\n",
              "    (pool1_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2_relu_3x3_reduce): ReLU(inplace=True)\n",
              "    (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2_relu_3x3): ReLU(inplace=True)\n",
              "    (pool2_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  )\n",
              "  (inception_a): InceptionA(\n",
              "    (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_1x1): ReLU(inplace=True)\n",
              "    (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_3x3_reduce): ReLU(inplace=True)\n",
              "    (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_3x3): ReLU(inplace=True)\n",
              "    (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "    (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_double_3x3_1): ReLU(inplace=True)\n",
              "    (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_double_3x3_2): ReLU(inplace=True)\n",
              "    (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
              "    (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_pool_proj): ReLU(inplace=True)\n",
              "  )\n",
              "  (inception_b): InceptionB(\n",
              "    (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_1x1): ReLU(inplace=True)\n",
              "    (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_3x3_reduce): ReLU(inplace=True)\n",
              "    (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_3x3): ReLU(inplace=True)\n",
              "    (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "    (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_double_3x3_1): ReLU(inplace=True)\n",
              "    (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_double_3x3_2): ReLU(inplace=True)\n",
              "    (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
              "    (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_pool_proj): ReLU(inplace=True)\n",
              "  )\n",
              "  (inception_c): InceptionC(\n",
              "    (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3c_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "    (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3c_relu_double_3x3_1): ReLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsejFJos1BgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4d968dc4-9270-46a5-d81b-215d28573382"
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 28.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 34.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 38.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 39.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 41.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 43.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 43.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 43.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 40.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 102kB 37.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 112kB 37.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 122kB 37.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 133kB 37.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 37.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 37.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 37.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 37.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 37.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 194kB 37.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (46.1.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPefC0uo0lw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. tensorboardXの保存クラスを呼び出します\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "# 2. フォルダ「tbX」に保存させるwriterを用意します\n",
        "# フォルダ「tbX」はなければ自動で作成されます\n",
        "writer = SummaryWriter(\"./tbX/\")\n",
        "\n",
        "\n",
        "# 3. ネットワークに流し込むダミーデータを作成します\n",
        "batch_size = 1\n",
        "dummy_img = torch.rand(batch_size, 3, 224, 224)\n",
        "\n",
        "# 4. netに対して、ダミーデータである\n",
        "# dummy_imgを流したときのgraphをwriterに保存させます\n",
        "writer.add_graph(net, (dummy_img, ))\n",
        "writer.close()\n",
        "\n",
        "\n",
        "# 5. コマンドプロンプトを開き、フォルダtbXがあるフォルダまで移動して、\n",
        "# 以下のコマンドを実行します\n",
        "\n",
        "# tensorboard --logdir=\"./tbX/\"\n",
        "\n",
        "# その後、http://localhost:6006 にアクセスします\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_BbpGor0lw4",
        "colab_type": "text"
      },
      "source": [
        "# ECOの3D Netモジュール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMqwPDfz0lw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resnet_3D_3(nn.Module):\n",
        "    '''Resnet_3D_3'''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet_3D_3, self).__init__()\n",
        "        \n",
        "        self.res3a_2 = nn.Conv3d(96, 128, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        self.res3a_bn = nn.BatchNorm3d(\n",
        "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res3a_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.res3b_1 = nn.Conv3d(128, 128, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        self.res3b_1_bn = nn.BatchNorm3d(\n",
        "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res3b_1_relu = nn.ReLU(inplace=True)\n",
        "        self.res3b_2 = nn.Conv3d(128, 128, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        self.res3b_bn = nn.BatchNorm3d(\n",
        "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res3b_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        residual = self.res3a_2(x)\n",
        "        out = self.res3a_bn(residual)\n",
        "        out = self.res3a_relu(out)\n",
        "\n",
        "        out = self.res3b_1(out)\n",
        "        out = self.res3b_1_bn(out)\n",
        "        out = self.res3b_relu(out)\n",
        "        out = self.res3b_2(out)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        out = self.res3b_bn(out)\n",
        "        out = self.res3b_relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tfcFHYu0lw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resnet_3D_4(nn.Module):\n",
        "    '''Resnet_3D_4'''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet_3D_4, self).__init__()\n",
        "\n",
        "        self.res4a_1 = nn.Conv3d(128, 256, kernel_size=(\n",
        "            3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        self.res4a_1_bn = nn.BatchNorm3d(\n",
        "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res4a_1_relu = nn.ReLU(inplace=True)\n",
        "        self.res4a_2 = nn.Conv3d(256, 256, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        self.res4a_down = nn.Conv3d(128, 256, kernel_size=(\n",
        "            3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        \n",
        "        self.res4a_bn = nn.BatchNorm3d(\n",
        "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res4a_relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.res4b_1 = nn.Conv3d(256, 256, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        self.res4b_1_bn = nn.BatchNorm3d(\n",
        "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res4b_1_relu = nn.ReLU(inplace=True)\n",
        "        self.res4b_2 = nn.Conv3d(256, 256, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        self.res4b_bn = nn.BatchNorm3d(\n",
        "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res4b_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.res4a_down(x)\n",
        "\n",
        "        out = self.res4a_1(x)\n",
        "        out = self.res4a_1_bn(out)\n",
        "        out = self.res4a_1_relu(out)\n",
        "\n",
        "        out = self.res4a_2(out)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        residual2 = out\n",
        "\n",
        "        out = self.res4a_bn(out)\n",
        "        out = self.res4a_relu(out)\n",
        "\n",
        "        out = self.res4b_1(out)\n",
        "\n",
        "        out = self.res4b_1_bn(out)\n",
        "        out = self.res4b_1_relu(out)\n",
        "\n",
        "        out = self.res4b_2(out)\n",
        "\n",
        "        out += residual2\n",
        "\n",
        "        out = self.res4b_bn(out)\n",
        "        out = self.res4b_relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wZFAayU0lxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resnet_3D_5(nn.Module):\n",
        "    '''Resnet_3D_5'''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet_3D_5, self).__init__()\n",
        "        \n",
        "        self.res5a_1 = nn.Conv3d(256, 512, kernel_size=(\n",
        "            3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        self.res5a_1_bn = nn.BatchNorm3d(\n",
        "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res5a_1_relu = nn.ReLU(inplace=True)\n",
        "        self.res5a_2 = nn.Conv3d(512, 512, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        self.res5a_down = nn.Conv3d(256, 512, kernel_size=(\n",
        "            3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        \n",
        "        self.res5a_bn = nn.BatchNorm3d(\n",
        "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res5a_relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.res5b_1 = nn.Conv3d(512, 512, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        self.res5b_1_bn = nn.BatchNorm3d(\n",
        "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res5b_1_relu = nn.ReLU(inplace=True)\n",
        "        self.res5b_2 = nn.Conv3d(512, 512, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        self.res5b_bn = nn.BatchNorm3d(\n",
        "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res5b_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.res5a_down(x)\n",
        "\n",
        "        out = self.res5a_1(x)\n",
        "        out = self.res5a_1_bn(out)\n",
        "        out = self.res5a_1_relu(out)\n",
        "\n",
        "        out = self.res5a_2(out)\n",
        "\n",
        "        out += residual  # res5a\n",
        "\n",
        "        residual2 = out\n",
        "\n",
        "        out = self.res5a_bn(out)\n",
        "        out = self.res5a_relu(out)\n",
        "\n",
        "        out = self.res5b_1(out)\n",
        "\n",
        "        out = self.res5b_1_bn(out)\n",
        "        out = self.res5b_1_relu(out)\n",
        "\n",
        "        out = self.res5b_2(out)\n",
        "\n",
        "        out += residual2  # res5b\n",
        "\n",
        "        out = self.res5b_bn(out)\n",
        "        out = self.res5b_relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAI9pemZ0lxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ECO_3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ECO_3D, self).__init__()\n",
        "\n",
        "        # 3D_Resnetジュール\n",
        "        self.res_3d_3 = Resnet_3D_3()\n",
        "        self.res_3d_4 = Resnet_3D_4()\n",
        "        self.res_3d_5 = Resnet_3D_5()\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.global_pool = nn.AvgPool3d(\n",
        "            kernel_size=(4, 7, 7), stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        入力xのサイズtorch.Size([batch_num,frames, 96, 28, 28]))\n",
        "        '''\n",
        "        out = torch.transpose(x, 1, 2)  # テンソルの順番入れ替え\n",
        "        out = self.res_3d_3(out)\n",
        "        out = self.res_3d_4(out)\n",
        "        out = self.res_3d_5(out)\n",
        "        out = self.global_pool(out)\n",
        "        \n",
        "        # テンソルサイズを変更\n",
        "        # torch.Size([batch_num, 512, 1, 1, 1])からtorch.Size([batch_num, 512])へ\n",
        "        out =out.view(out.size()[0], out.size()[1])\n",
        "        \n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6i2XOuV0lxH",
        "colab_type": "text"
      },
      "source": [
        "## 動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4gA7aGD0lxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "fcf9d2b0-ad1d-4707-f37a-da6466ae7efc"
      },
      "source": [
        "# モデルの用意\n",
        "net = ECO_3D()\n",
        "net.train()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ECO_3D(\n",
              "  (res_3d_3): Resnet_3D_3(\n",
              "    (res3a_2): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res3a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res3a_relu): ReLU(inplace=True)\n",
              "    (res3b_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res3b_1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res3b_1_relu): ReLU(inplace=True)\n",
              "    (res3b_2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res3b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res3b_relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (res_3d_4): Resnet_3D_4(\n",
              "    (res4a_1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "    (res4a_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res4a_1_relu): ReLU(inplace=True)\n",
              "    (res4a_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res4a_down): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "    (res4a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res4a_relu): ReLU(inplace=True)\n",
              "    (res4b_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res4b_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res4b_1_relu): ReLU(inplace=True)\n",
              "    (res4b_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res4b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res4b_relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (res_3d_5): Resnet_3D_5(\n",
              "    (res5a_1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "    (res5a_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res5a_1_relu): ReLU(inplace=True)\n",
              "    (res5a_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res5a_down): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "    (res5a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res5a_relu): ReLU(inplace=True)\n",
              "    (res5b_1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res5b_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res5b_1_relu): ReLU(inplace=True)\n",
              "    (res5b_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res5b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res5b_relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (global_pool): AvgPool3d(kernel_size=(4, 7, 7), stride=1, padding=0)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiM8jiWK0lxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. tensorboardXの保存クラスを呼び出します\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "# 2. フォルダ「tbX」に保存させるwriterを用意します\n",
        "# フォルダ「tbX」はなければ自動で作成されます\n",
        "writer = SummaryWriter(\"./tbX/\")\n",
        "\n",
        "\n",
        "# 3. ネットワークに流し込むダミーデータを作成します\n",
        "batch_size = 1\n",
        "dummy_img = torch.rand(batch_size, 16, 96, 28, 28)\n",
        "\n",
        "# 4. netに対して、ダミーデータである\n",
        "# dummy_imgを流したときのgraphをwriterに保存させます\n",
        "writer.add_graph(net, (dummy_img, ))\n",
        "writer.close()\n",
        "\n",
        "\n",
        "# 5. コマンドプロンプトを開き、フォルダtbXがあるフォルダまで移動して、\n",
        "# 以下のコマンドを実行します\n",
        "\n",
        "# tensorboard --logdir=\"./tbX/\"\n",
        "\n",
        "# その後、http://localhost:6006 にアクセスします\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u59m3lfi4RZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a7eff51a-76f4-406d-cf8a-fb61a2a3b8d4"
      },
      "source": [
        "!git clone https://github.com/activitynet/ActivityNet.git\n",
        "%cd ActivityNet/Crawler/Kinetics"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ActivityNet'...\n",
            "remote: Enumerating objects: 253, done.\u001b[K\n",
            "remote: Total 253 (delta 0), reused 0 (delta 0), pack-reused 253\u001b[K\n",
            "Receiving objects: 100% (253/253), 44.58 MiB | 30.01 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n",
            "/content/pytorch_advanced/9_video_classification_eco/ActivityNet/Crawler/Kinetics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx3HgZh54a69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "34b2ce83-3a5b-4a76-d9bb-8ddd08fb05be"
      },
      "source": [
        "!source deactivate\n",
        "\n",
        "!conda env create -f ./9_video_classification_eco/video_download/environment.yml"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: deactivate: No such file or directory\n",
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcNyrfWU4kuq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a4e910c1-2c3c-4a2b-ffd2-ceb389d052b9"
      },
      "source": [
        "pip install --upgrade youtube-dl"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtube-dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/46/31aa255d531b3d77880fc5492396ba421525b926a2f4db8be883495d1bdd/youtube_dl-2020.5.3-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 38.2MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2020.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af1m1slV4f0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1114e64f-5bd0-4691-993e-fec928ea4ee4"
      },
      "source": [
        "pip install --upgrade joblib"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: joblib in /usr/local/lib/python3.6/dist-packages (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BqyP-9w5Ac5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6bf3024-96bb-451a-fa2c-43f8a8840533"
      },
      "source": [
        "%cd  /content/pytorch_advanced/9_video_classification_eco/"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch_advanced/9_video_classification_eco\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7DCPIZJ1WMm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a42545ab-1b60-486d-8cb5-0e282a91d90d"
      },
      "source": [
        "import os\n",
        "\n",
        "# フォルダ「data」が存在しない場合は作成する\n",
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "    \n",
        "# フォルダ「kinetics_videos」が存在しない場合は作成する\n",
        "data_dir = \"./data/kinetics_videos/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "    \n",
        "    \n",
        "# フォルダ「video_download」のpytnonファイル「download.py」を実行します\n",
        "# 取得するyoutubeデータはフォルダ「video_download」のkinetics-400_val_8videos.csvに記載した8動画です\n",
        "# 保存先はフォルダ「data」内のフォルダ「kinetics_videos」です\n",
        "!python2 ./video_download/download.py ./video_download/kinetics-400_val_8videos.csv /content/pytorch_advanced/9_video_classification_eco/data/kinetics_videos/"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/kinetics/aab9e9b9-93ac-4faf-a12f-2d0855b18dc3.%(ext)s\n",
            "/tmp/kinetics/062c6948-122a-4bfe-8b87-e0680a66fd06.%(ext)s\n",
            "/tmp/kinetics/b8a301b0-3ec4-46f4-b3bd-be7e20e699a7.%(ext)s\n",
            "/tmp/kinetics/92d95f9c-caec-4097-a3a4-ffa495aab968.%(ext)s\n",
            "/tmp/kinetics/a5c751e1-a3f0-4620-92bb-a91a8e53c192.%(ext)s\n",
            "/tmp/kinetics/524b5b7e-3327-4cbb-880f-bafee4d22683.%(ext)s\n",
            "/tmp/kinetics/e43fc377-46df-4180-8522-aa0122b4b713.%(ext)s\n",
            "/tmp/kinetics/ccd88db8-f13f-44f9-bb23-456b0330c11c.%(ext)s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvEu5DWz1ekO",
        "colab_type": "text"
      },
      "source": [
        "# 9.4.2 動画をframeごとに画像データに変換\n",
        "本ファイルでは、ダウンロードした動画をframeごとにjpeg形式の画像データに変換します。\n",
        "\n",
        "# 事前準備\n",
        "ffmepgが入っていない場合には、 以下のコマンドをターミナルで実行し、Ubuntuにてffmpegをインストールします。\n",
        "\n",
        "sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oXBE8LI1m7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "077af54d-d370-4bfb-ba7c-1da3a6b29f93"
      },
      "source": [
        "import os\n",
        "import subprocess  # ターミナルで実行するコマンドを実行できる\n",
        "\n",
        "\n",
        "# 動画が保存されたフォルダ「kinetics_videos」にある、クラスの種類とパスを取得\n",
        "dir_path = './data/kinetics_videos'\n",
        "class_list = os.listdir(path=dir_path)\n",
        "print(class_list)\n",
        "\n",
        "# 各クラスの動画ファイルを画像ファイルに変換する\n",
        "for class_list_i in (class_list):  # クラスごとのループ\n",
        "\n",
        "    # クラスのフォルダへのパスを取得\n",
        "    class_path = os.path.join(dir_path, class_list_i)\n",
        "\n",
        "    # 各クラスのフォルダ内の動画ファイルをひとつずつ処理するループ\n",
        "    for file_name in os.listdir(class_path):\n",
        "\n",
        "        # ファイル名と拡張子に分割\n",
        "        name, ext = os.path.splitext(file_name)\n",
        "\n",
        "        # mp4ファイルでない、フォルダなどは処理しない\n",
        "        if ext != '.mp4':\n",
        "            continue\n",
        "\n",
        "        # 動画ファイルを画像に分割して保存するフォルダ名を取得\n",
        "        dst_directory_path = os.path.join(class_path, name)\n",
        "\n",
        "        # 上記の画像保存フォルダがなければ作成\n",
        "        if not os.path.exists(dst_directory_path):\n",
        "            os.mkdir(dst_directory_path)\n",
        "\n",
        "        # 動画ファイルへのパスを取得\n",
        "        video_file_path = os.path.join(class_path, file_name)\n",
        "\n",
        "        # ffmpegを実行させ、動画ファイルをjpgにする （高さは256ピクセルで幅はアスペクト比を変えない）\n",
        "        # kineticsの動画の場合10秒になっており、大体300ファイルになる（30 frames /sec）\n",
        "        cmd = 'ffmpeg -i \\\"{}\\\" -vf scale=-1:256 \\\"{}/image_%05d.jpg\\\"'.format(\n",
        "            video_file_path, dst_directory_path)\n",
        "        print(cmd)\n",
        "        subprocess.call(cmd, shell=True)\n",
        "        print('\\n')\n",
        "\n",
        "print(\"動画ファイルを画像ファイルに変換しました。\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bungee jumping', 'arm wrestling']\n",
            "ffmpeg -i \"./data/kinetics_videos/bungee jumping/TUvSX0pYu4o_000002_000012.mp4\" -vf scale=-1:256 \"./data/kinetics_videos/bungee jumping/TUvSX0pYu4o_000002_000012/image_%05d.jpg\"\n",
            "\n",
            "\n",
            "ffmpeg -i \"./data/kinetics_videos/bungee jumping/dAeUFSdYG1I_000010_000020.mp4\" -vf scale=-1:256 \"./data/kinetics_videos/bungee jumping/dAeUFSdYG1I_000010_000020/image_%05d.jpg\"\n",
            "\n",
            "\n",
            "ffmpeg -i \"./data/kinetics_videos/bungee jumping/b6yQZjPE26c_000023_000033.mp4\" -vf scale=-1:256 \"./data/kinetics_videos/bungee jumping/b6yQZjPE26c_000023_000033/image_%05d.jpg\"\n",
            "\n",
            "\n",
            "ffmpeg -i \"./data/kinetics_videos/bungee jumping/zkXOcxGnUhs_000025_000035.mp4\" -vf scale=-1:256 \"./data/kinetics_videos/bungee jumping/zkXOcxGnUhs_000025_000035/image_%05d.jpg\"\n",
            "\n",
            "\n",
            "ffmpeg -i \"./data/kinetics_videos/arm wrestling/BdMiTo_OtnU_000024_000034.mp4\" -vf scale=-1:256 \"./data/kinetics_videos/arm wrestling/BdMiTo_OtnU_000024_000034/image_%05d.jpg\"\n",
            "\n",
            "\n",
            "ffmpeg -i \"./data/kinetics_videos/arm wrestling/C4lCVBZ3ux0_000028_000038.mp4\" -vf scale=-1:256 \"./data/kinetics_videos/arm wrestling/C4lCVBZ3ux0_000028_000038/image_%05d.jpg\"\n",
            "\n",
            "\n",
            "ffmpeg -i \"./data/kinetics_videos/arm wrestling/5JzkrOVhPOw_000027_000037.mp4\" -vf scale=-1:256 \"./data/kinetics_videos/arm wrestling/5JzkrOVhPOw_000027_000037/image_%05d.jpg\"\n",
            "\n",
            "\n",
            "ffmpeg -i \"./data/kinetics_videos/arm wrestling/ehLnj7pXnYE_000027_000037.mp4\" -vf scale=-1:256 \"./data/kinetics_videos/arm wrestling/ehLnj7pXnYE_000027_000037/image_%05d.jpg\"\n",
            "\n",
            "\n",
            "動画ファイルを画像ファイルに変換しました。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAcku6KQ1tA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn\n",
        "\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emavt8Iy1v92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8e1cfeb1-df41-427c-f4dd-96d9d948d0f1"
      },
      "source": [
        "def make_datapath_list(root_path):\n",
        "    \"\"\"\n",
        "    動画を画像データにしたフォルダへのファイルパスリストを作成する。\n",
        "    root_path : str、データフォルダへのrootパス\n",
        "    Returns：ret : video_list、動画を画像データにしたフォルダへのファイルパスリスト\n",
        "    \"\"\"\n",
        "\n",
        "    # 動画を画像データにしたフォルダへのファイルパスリスト\n",
        "    video_list = list()\n",
        "\n",
        "    # root_pathにある、クラスの種類とパスを取得\n",
        "    class_list = os.listdir(path=root_path)\n",
        "\n",
        "    # 各クラスの動画ファイルを画像化したフォルダへのパスを取得\n",
        "    for class_list_i in (class_list):  # クラスごとのループ\n",
        "\n",
        "        # クラスのフォルダへのパスを取得\n",
        "        class_path = os.path.join(root_path, class_list_i)\n",
        "\n",
        "        # 各クラスのフォルダ内の画像フォルダを取得するループ\n",
        "        for file_name in os.listdir(class_path):\n",
        "\n",
        "            # ファイル名と拡張子に分割\n",
        "            name, ext = os.path.splitext(file_name)\n",
        "\n",
        "            # フォルダでないmp4ファイルは無視\n",
        "            if ext == '.mp4':\n",
        "                continue\n",
        "\n",
        "            # 動画ファイルを画像に分割して保存したフォルダのパスを取得\n",
        "            video_img_directory_path = os.path.join(class_path, name)\n",
        "\n",
        "            # vieo_listに追加\n",
        "            video_list.append(video_img_directory_path)\n",
        "\n",
        "    return video_list\n",
        "\n",
        "\n",
        "# 動作確認\n",
        "root_path = './data/kinetics_videos/'\n",
        "video_list = make_datapath_list(root_path)\n",
        "print(video_list)\n",
        "print(video_list[0])\n",
        "print(video_list[1])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['./data/kinetics_videos/bungee jumping/dAeUFSdYG1I_000010_000020', './data/kinetics_videos/bungee jumping/zkXOcxGnUhs_000025_000035', './data/kinetics_videos/bungee jumping/TUvSX0pYu4o_000002_000012', './data/kinetics_videos/bungee jumping/b6yQZjPE26c_000023_000033', './data/kinetics_videos/arm wrestling/5JzkrOVhPOw_000027_000037', './data/kinetics_videos/arm wrestling/C4lCVBZ3ux0_000028_000038', './data/kinetics_videos/arm wrestling/ehLnj7pXnYE_000027_000037', './data/kinetics_videos/arm wrestling/BdMiTo_OtnU_000024_000034']\n",
            "./data/kinetics_videos/bungee jumping/dAeUFSdYG1I_000010_000020\n",
            "./data/kinetics_videos/bungee jumping/zkXOcxGnUhs_000025_000035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx6eU90L5gTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN7Y89qk5ieB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# フォルダ「weights」が存在しない場合は作成する\n",
        "weights_dir = \"./weights/\"\n",
        "if not os.path.exists(weights_dir):\n",
        "    os.mkdir(weights_dir)\n",
        "\n",
        "# フォルダ「weights」に学習済みモデル「ECO_Lite_rgb_model_Kinetics.pth.tar」をダウンロードして配置してください。\n",
        "# https://github.com/mzolfaghari/ECO-pytorch の\n",
        "# https://drive.google.com/open?id=1XNIq7byciKgrn011jLBggd2g79jKX4uD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHGUXvL25lrS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15b9fb39-0595-4364-ab93-d4968a313dce"
      },
      "source": [
        "from utils.kinetics400_eco_dataloader import make_datapath_list, VideoTransform, get_label_id_dictionary, VideoDataset\n",
        "\n",
        "# vieo_listの作成\n",
        "root_path = './data/kinetics_videos/'\n",
        "video_list = make_datapath_list(root_path)\n",
        "\n",
        "# 前処理の設定\n",
        "resize, crop_size = 224, 224\n",
        "mean, std = [104, 117, 123], [1, 1, 1]\n",
        "video_transform = VideoTransform(resize, crop_size, mean, std)\n",
        "\n",
        "# ラベル辞書の作成\n",
        "label_dicitionary_path = './video_download/kinetics_400_label_dicitionary.csv'\n",
        "label_id_dict, id_label_dict = get_label_id_dictionary(label_dicitionary_path)\n",
        "\n",
        "# Datasetの作成\n",
        "# num_segments は 動画を何分割して使用するのかを決める\n",
        "val_dataset = VideoDataset(video_list, label_id_dict, num_segments=16,\n",
        "                           phase=\"val\", transform=video_transform, img_tmpl='image_{:05d}.jpg')\n",
        "\n",
        "# DataLoaderにします\n",
        "batch_size = 8\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 動作確認\n",
        "batch_iterator = iter(val_dataloader)  # イテレータに変換\n",
        "imgs_transformeds, labels, label_ids, dir_path = next(\n",
        "    batch_iterator)  # 1番目の要素を取り出す\n",
        "print(imgs_transformeds.shape)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 16, 3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GkIRvIA5ogr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils.eco import ECO_2D, ECO_3D\n",
        "\n",
        "\n",
        "class ECO_Lite(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ECO_Lite, self).__init__()\n",
        "\n",
        "        # 2D Netモジュール\n",
        "        self.eco_2d = ECO_2D()\n",
        "\n",
        "        # 3D Netモジュール\n",
        "        self.eco_3d = ECO_3D()\n",
        "\n",
        "        # クラス分類の全結合層\n",
        "        self.fc_final = nn.Linear(in_features=512, out_features=400, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        入力xはtorch.Size([batch_num, num_segments=16, 3, 224, 224]))\n",
        "        '''\n",
        "\n",
        "        # 入力xの各次元のサイズを取得する\n",
        "        bs, ns, c, h, w = x.shape\n",
        "\n",
        "        # xを(bs*ns, c, h, w)にサイズ変換する\n",
        "        out = x.view(-1, c, h, w)\n",
        "        # （注釈）\n",
        "        # PyTorchのConv2Dは入力のサイズが(batch_num, c, h, w)しか受け付けないため\n",
        "        # (batch_num, num_segments, c, h, w)は処理できない\n",
        "        # 今は2次元画像を独立に処理するので、num_segmentsはbatch_numの次元に押し込んでも良いため\n",
        "        # (batch_num×num_segments, c, h, w)にサイズを変換する\n",
        "\n",
        "        # 2D Netモジュール 出力torch.Size([batch_num×16, 96, 28, 28])\n",
        "        out = self.eco_2d(out)\n",
        "\n",
        "        # 2次元画像をテンソルを3次元用に変換する\n",
        "        # num_segmentsをbatch_numの次元に押し込んだものを元に戻す\n",
        "        out = out.view(-1, ns, 96, 28, 28)\n",
        "\n",
        "        # 3D Netモジュール 出力torch.Size([batch_num, 512])\n",
        "        out = self.eco_3d(out)\n",
        "\n",
        "        # クラス分類の全結合層　出力torch.Size([batch_num, class_num=400])\n",
        "        out = self.fc_final(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lifMrJ9C5q_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afb75334-ecbb-4e79-e4db-78d0dd8e13f8"
      },
      "source": [
        "net = ECO_Lite()\n",
        "net"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ECO_Lite(\n",
              "  (eco_2d): ECO_2D(\n",
              "    (basic_conv): BasicConv(\n",
              "      (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "      (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1_relu_7x7): ReLU(inplace=True)\n",
              "      (pool1_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "      (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2_relu_3x3_reduce): ReLU(inplace=True)\n",
              "      (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2_relu_3x3): ReLU(inplace=True)\n",
              "      (pool2_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    )\n",
              "    (inception_a): InceptionA(\n",
              "      (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_1x1): ReLU(inplace=True)\n",
              "      (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_3x3_reduce): ReLU(inplace=True)\n",
              "      (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_3x3): ReLU(inplace=True)\n",
              "      (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "      (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_double_3x3_1): ReLU(inplace=True)\n",
              "      (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_double_3x3_2): ReLU(inplace=True)\n",
              "      (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
              "      (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_pool_proj): ReLU(inplace=True)\n",
              "    )\n",
              "    (inception_b): InceptionB(\n",
              "      (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_1x1): ReLU(inplace=True)\n",
              "      (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_3x3_reduce): ReLU(inplace=True)\n",
              "      (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_3x3): ReLU(inplace=True)\n",
              "      (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "      (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_double_3x3_1): ReLU(inplace=True)\n",
              "      (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_double_3x3_2): ReLU(inplace=True)\n",
              "      (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
              "      (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_pool_proj): ReLU(inplace=True)\n",
              "    )\n",
              "    (inception_c): InceptionC(\n",
              "      (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3c_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "      (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3c_relu_double_3x3_1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (eco_3d): ECO_3D(\n",
              "    (res_3d_3): Resnet_3D_3(\n",
              "      (res3a_2): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res3a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res3a_relu): ReLU(inplace=True)\n",
              "      (res3b_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res3b_1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res3b_1_relu): ReLU(inplace=True)\n",
              "      (res3b_2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res3b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res3b_relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (res_3d_4): Resnet_3D_4(\n",
              "      (res4a_1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      (res4a_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res4a_1_relu): ReLU(inplace=True)\n",
              "      (res4a_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res4a_down): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      (res4a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res4a_relu): ReLU(inplace=True)\n",
              "      (res4b_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res4b_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res4b_1_relu): ReLU(inplace=True)\n",
              "      (res4b_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res4b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res4b_relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (res_3d_5): Resnet_3D_5(\n",
              "      (res5a_1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      (res5a_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res5a_1_relu): ReLU(inplace=True)\n",
              "      (res5a_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res5a_down): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      (res5a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res5a_relu): ReLU(inplace=True)\n",
              "      (res5b_1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res5b_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res5b_1_relu): ReLU(inplace=True)\n",
              "      (res5b_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res5b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res5b_relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): AvgPool3d(kernel_size=(4, 7, 7), stride=1, padding=0)\n",
              "  )\n",
              "  (fc_final): Linear(in_features=512, out_features=400, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9PNpnCm5uMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bcf74b5-8ac4-44b2-f8ac-2f0c1aa9b0c5"
      },
      "source": [
        "\n",
        "# 学習済みモデルをロードする関数の定義\n",
        "\n",
        "\n",
        "def load_pretrained_ECO(model_dict, pretrained_model_dict):\n",
        "    '''ECOの学習済みモデルをロードする関数\n",
        "    今回構築したECOは学習済みモデルとレイヤーの順番は同じだが名前が異なる\n",
        "    '''\n",
        "\n",
        "    # 現在のネットワークモデルのパラメータ名\n",
        "    param_names = []  # パラメータの名前を格納していく\n",
        "    for name, param in model_dict.items():\n",
        "        param_names.append(name)\n",
        "\n",
        "    # 現在のネットワークの情報をコピーして新たなstate_dictを作成\n",
        "    new_state_dict = model_dict.copy()\n",
        "\n",
        "    # 新たなstate_dictに学習済みの値を代入\n",
        "    print(\"学習済みのパラメータをロードします\")\n",
        "    for index, (key_name, value) in enumerate(pretrained_model_dict.items()):\n",
        "        name = param_names[index]  # 現在のネットワークでのパラメータ名を取得\n",
        "        new_state_dict[name] = value  # 値を入れる\n",
        "\n",
        "        # 何から何にロードされたのかを表示\n",
        "        print(str(key_name)+\"→\"+str(name))\n",
        "\n",
        "    return new_state_dict\n",
        "\n",
        "\n",
        "# 学習済みモデルをロード\n",
        "net_model_ECO = \"./weights/ECO_Lite_rgb_model_Kinetics.pth.tar\"\n",
        "pretrained_model = torch.load(net_model_ECO, map_location='cpu')\n",
        "pretrained_model_dict = pretrained_model['state_dict']\n",
        "# （注釈）\n",
        "# pthがtarで圧縮されているのは、state_dict以外の情報も一緒に保存されているため。\n",
        "# そのため読み込むときは辞書型変数になっているので['state_dict']で指定する。\n",
        "\n",
        "# 現在のモデルの変数名などを取得\n",
        "model_dict = net.state_dict()\n",
        "\n",
        "# 学習済みモデルのstate_dictを取得\n",
        "new_state_dict = load_pretrained_ECO(model_dict, pretrained_model_dict)\n",
        "\n",
        "# 学習済みモデルのパラメータを代入\n",
        "net.eval()  # ECOネットワークを推論モードに\n",
        "net.load_state_dict(new_state_dict)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "学習済みのパラメータをロードします\n",
            "module.base_model.conv1_7x7_s2.weight→eco_2d.basic_conv.conv1_7x7_s2.weight\n",
            "module.base_model.conv1_7x7_s2.bias→eco_2d.basic_conv.conv1_7x7_s2.bias\n",
            "module.base_model.conv1_7x7_s2_bn.weight→eco_2d.basic_conv.conv1_7x7_s2_bn.weight\n",
            "module.base_model.conv1_7x7_s2_bn.bias→eco_2d.basic_conv.conv1_7x7_s2_bn.bias\n",
            "module.base_model.conv1_7x7_s2_bn.running_mean→eco_2d.basic_conv.conv1_7x7_s2_bn.running_mean\n",
            "module.base_model.conv1_7x7_s2_bn.running_var→eco_2d.basic_conv.conv1_7x7_s2_bn.running_var\n",
            "module.base_model.conv1_7x7_s2_bn.num_batches_tracked→eco_2d.basic_conv.conv1_7x7_s2_bn.num_batches_tracked\n",
            "module.base_model.conv2_3x3_reduce.weight→eco_2d.basic_conv.conv2_3x3_reduce.weight\n",
            "module.base_model.conv2_3x3_reduce.bias→eco_2d.basic_conv.conv2_3x3_reduce.bias\n",
            "module.base_model.conv2_3x3_reduce_bn.weight→eco_2d.basic_conv.conv2_3x3_reduce_bn.weight\n",
            "module.base_model.conv2_3x3_reduce_bn.bias→eco_2d.basic_conv.conv2_3x3_reduce_bn.bias\n",
            "module.base_model.conv2_3x3_reduce_bn.running_mean→eco_2d.basic_conv.conv2_3x3_reduce_bn.running_mean\n",
            "module.base_model.conv2_3x3_reduce_bn.running_var→eco_2d.basic_conv.conv2_3x3_reduce_bn.running_var\n",
            "module.base_model.conv2_3x3_reduce_bn.num_batches_tracked→eco_2d.basic_conv.conv2_3x3_reduce_bn.num_batches_tracked\n",
            "module.base_model.conv2_3x3.weight→eco_2d.basic_conv.conv2_3x3.weight\n",
            "module.base_model.conv2_3x3.bias→eco_2d.basic_conv.conv2_3x3.bias\n",
            "module.base_model.conv2_3x3_bn.weight→eco_2d.basic_conv.conv2_3x3_bn.weight\n",
            "module.base_model.conv2_3x3_bn.bias→eco_2d.basic_conv.conv2_3x3_bn.bias\n",
            "module.base_model.conv2_3x3_bn.running_mean→eco_2d.basic_conv.conv2_3x3_bn.running_mean\n",
            "module.base_model.conv2_3x3_bn.running_var→eco_2d.basic_conv.conv2_3x3_bn.running_var\n",
            "module.base_model.conv2_3x3_bn.num_batches_tracked→eco_2d.basic_conv.conv2_3x3_bn.num_batches_tracked\n",
            "module.base_model.inception_3a_1x1.weight→eco_2d.inception_a.inception_3a_1x1.weight\n",
            "module.base_model.inception_3a_1x1.bias→eco_2d.inception_a.inception_3a_1x1.bias\n",
            "module.base_model.inception_3a_1x1_bn.weight→eco_2d.inception_a.inception_3a_1x1_bn.weight\n",
            "module.base_model.inception_3a_1x1_bn.bias→eco_2d.inception_a.inception_3a_1x1_bn.bias\n",
            "module.base_model.inception_3a_1x1_bn.running_mean→eco_2d.inception_a.inception_3a_1x1_bn.running_mean\n",
            "module.base_model.inception_3a_1x1_bn.running_var→eco_2d.inception_a.inception_3a_1x1_bn.running_var\n",
            "module.base_model.inception_3a_1x1_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_1x1_bn.num_batches_tracked\n",
            "module.base_model.inception_3a_3x3_reduce.weight→eco_2d.inception_a.inception_3a_3x3_reduce.weight\n",
            "module.base_model.inception_3a_3x3_reduce.bias→eco_2d.inception_a.inception_3a_3x3_reduce.bias\n",
            "module.base_model.inception_3a_3x3_reduce_bn.weight→eco_2d.inception_a.inception_3a_3x3_reduce_bn.weight\n",
            "module.base_model.inception_3a_3x3_reduce_bn.bias→eco_2d.inception_a.inception_3a_3x3_reduce_bn.bias\n",
            "module.base_model.inception_3a_3x3_reduce_bn.running_mean→eco_2d.inception_a.inception_3a_3x3_reduce_bn.running_mean\n",
            "module.base_model.inception_3a_3x3_reduce_bn.running_var→eco_2d.inception_a.inception_3a_3x3_reduce_bn.running_var\n",
            "module.base_model.inception_3a_3x3_reduce_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_3x3_reduce_bn.num_batches_tracked\n",
            "module.base_model.inception_3a_3x3.weight→eco_2d.inception_a.inception_3a_3x3.weight\n",
            "module.base_model.inception_3a_3x3.bias→eco_2d.inception_a.inception_3a_3x3.bias\n",
            "module.base_model.inception_3a_3x3_bn.weight→eco_2d.inception_a.inception_3a_3x3_bn.weight\n",
            "module.base_model.inception_3a_3x3_bn.bias→eco_2d.inception_a.inception_3a_3x3_bn.bias\n",
            "module.base_model.inception_3a_3x3_bn.running_mean→eco_2d.inception_a.inception_3a_3x3_bn.running_mean\n",
            "module.base_model.inception_3a_3x3_bn.running_var→eco_2d.inception_a.inception_3a_3x3_bn.running_var\n",
            "module.base_model.inception_3a_3x3_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_3x3_bn.num_batches_tracked\n",
            "module.base_model.inception_3a_double_3x3_reduce.weight→eco_2d.inception_a.inception_3a_double_3x3_reduce.weight\n",
            "module.base_model.inception_3a_double_3x3_reduce.bias→eco_2d.inception_a.inception_3a_double_3x3_reduce.bias\n",
            "module.base_model.inception_3a_double_3x3_reduce_bn.weight→eco_2d.inception_a.inception_3a_double_3x3_reduce_bn.weight\n",
            "module.base_model.inception_3a_double_3x3_reduce_bn.bias→eco_2d.inception_a.inception_3a_double_3x3_reduce_bn.bias\n",
            "module.base_model.inception_3a_double_3x3_reduce_bn.running_mean→eco_2d.inception_a.inception_3a_double_3x3_reduce_bn.running_mean\n",
            "module.base_model.inception_3a_double_3x3_reduce_bn.running_var→eco_2d.inception_a.inception_3a_double_3x3_reduce_bn.running_var\n",
            "module.base_model.inception_3a_double_3x3_reduce_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_double_3x3_reduce_bn.num_batches_tracked\n",
            "module.base_model.inception_3a_double_3x3_1.weight→eco_2d.inception_a.inception_3a_double_3x3_1.weight\n",
            "module.base_model.inception_3a_double_3x3_1.bias→eco_2d.inception_a.inception_3a_double_3x3_1.bias\n",
            "module.base_model.inception_3a_double_3x3_1_bn.weight→eco_2d.inception_a.inception_3a_double_3x3_1_bn.weight\n",
            "module.base_model.inception_3a_double_3x3_1_bn.bias→eco_2d.inception_a.inception_3a_double_3x3_1_bn.bias\n",
            "module.base_model.inception_3a_double_3x3_1_bn.running_mean→eco_2d.inception_a.inception_3a_double_3x3_1_bn.running_mean\n",
            "module.base_model.inception_3a_double_3x3_1_bn.running_var→eco_2d.inception_a.inception_3a_double_3x3_1_bn.running_var\n",
            "module.base_model.inception_3a_double_3x3_1_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_double_3x3_1_bn.num_batches_tracked\n",
            "module.base_model.inception_3a_double_3x3_2.weight→eco_2d.inception_a.inception_3a_double_3x3_2.weight\n",
            "module.base_model.inception_3a_double_3x3_2.bias→eco_2d.inception_a.inception_3a_double_3x3_2.bias\n",
            "module.base_model.inception_3a_double_3x3_2_bn.weight→eco_2d.inception_a.inception_3a_double_3x3_2_bn.weight\n",
            "module.base_model.inception_3a_double_3x3_2_bn.bias→eco_2d.inception_a.inception_3a_double_3x3_2_bn.bias\n",
            "module.base_model.inception_3a_double_3x3_2_bn.running_mean→eco_2d.inception_a.inception_3a_double_3x3_2_bn.running_mean\n",
            "module.base_model.inception_3a_double_3x3_2_bn.running_var→eco_2d.inception_a.inception_3a_double_3x3_2_bn.running_var\n",
            "module.base_model.inception_3a_double_3x3_2_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_double_3x3_2_bn.num_batches_tracked\n",
            "module.base_model.inception_3a_pool_proj.weight→eco_2d.inception_a.inception_3a_pool_proj.weight\n",
            "module.base_model.inception_3a_pool_proj.bias→eco_2d.inception_a.inception_3a_pool_proj.bias\n",
            "module.base_model.inception_3a_pool_proj_bn.weight→eco_2d.inception_a.inception_3a_pool_proj_bn.weight\n",
            "module.base_model.inception_3a_pool_proj_bn.bias→eco_2d.inception_a.inception_3a_pool_proj_bn.bias\n",
            "module.base_model.inception_3a_pool_proj_bn.running_mean→eco_2d.inception_a.inception_3a_pool_proj_bn.running_mean\n",
            "module.base_model.inception_3a_pool_proj_bn.running_var→eco_2d.inception_a.inception_3a_pool_proj_bn.running_var\n",
            "module.base_model.inception_3a_pool_proj_bn.num_batches_tracked→eco_2d.inception_a.inception_3a_pool_proj_bn.num_batches_tracked\n",
            "module.base_model.inception_3b_1x1.weight→eco_2d.inception_b.inception_3b_1x1.weight\n",
            "module.base_model.inception_3b_1x1.bias→eco_2d.inception_b.inception_3b_1x1.bias\n",
            "module.base_model.inception_3b_1x1_bn.weight→eco_2d.inception_b.inception_3b_1x1_bn.weight\n",
            "module.base_model.inception_3b_1x1_bn.bias→eco_2d.inception_b.inception_3b_1x1_bn.bias\n",
            "module.base_model.inception_3b_1x1_bn.running_mean→eco_2d.inception_b.inception_3b_1x1_bn.running_mean\n",
            "module.base_model.inception_3b_1x1_bn.running_var→eco_2d.inception_b.inception_3b_1x1_bn.running_var\n",
            "module.base_model.inception_3b_1x1_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_1x1_bn.num_batches_tracked\n",
            "module.base_model.inception_3b_3x3_reduce.weight→eco_2d.inception_b.inception_3b_3x3_reduce.weight\n",
            "module.base_model.inception_3b_3x3_reduce.bias→eco_2d.inception_b.inception_3b_3x3_reduce.bias\n",
            "module.base_model.inception_3b_3x3_reduce_bn.weight→eco_2d.inception_b.inception_3b_3x3_reduce_bn.weight\n",
            "module.base_model.inception_3b_3x3_reduce_bn.bias→eco_2d.inception_b.inception_3b_3x3_reduce_bn.bias\n",
            "module.base_model.inception_3b_3x3_reduce_bn.running_mean→eco_2d.inception_b.inception_3b_3x3_reduce_bn.running_mean\n",
            "module.base_model.inception_3b_3x3_reduce_bn.running_var→eco_2d.inception_b.inception_3b_3x3_reduce_bn.running_var\n",
            "module.base_model.inception_3b_3x3_reduce_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_3x3_reduce_bn.num_batches_tracked\n",
            "module.base_model.inception_3b_3x3.weight→eco_2d.inception_b.inception_3b_3x3.weight\n",
            "module.base_model.inception_3b_3x3.bias→eco_2d.inception_b.inception_3b_3x3.bias\n",
            "module.base_model.inception_3b_3x3_bn.weight→eco_2d.inception_b.inception_3b_3x3_bn.weight\n",
            "module.base_model.inception_3b_3x3_bn.bias→eco_2d.inception_b.inception_3b_3x3_bn.bias\n",
            "module.base_model.inception_3b_3x3_bn.running_mean→eco_2d.inception_b.inception_3b_3x3_bn.running_mean\n",
            "module.base_model.inception_3b_3x3_bn.running_var→eco_2d.inception_b.inception_3b_3x3_bn.running_var\n",
            "module.base_model.inception_3b_3x3_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_3x3_bn.num_batches_tracked\n",
            "module.base_model.inception_3b_double_3x3_reduce.weight→eco_2d.inception_b.inception_3b_double_3x3_reduce.weight\n",
            "module.base_model.inception_3b_double_3x3_reduce.bias→eco_2d.inception_b.inception_3b_double_3x3_reduce.bias\n",
            "module.base_model.inception_3b_double_3x3_reduce_bn.weight→eco_2d.inception_b.inception_3b_double_3x3_reduce_bn.weight\n",
            "module.base_model.inception_3b_double_3x3_reduce_bn.bias→eco_2d.inception_b.inception_3b_double_3x3_reduce_bn.bias\n",
            "module.base_model.inception_3b_double_3x3_reduce_bn.running_mean→eco_2d.inception_b.inception_3b_double_3x3_reduce_bn.running_mean\n",
            "module.base_model.inception_3b_double_3x3_reduce_bn.running_var→eco_2d.inception_b.inception_3b_double_3x3_reduce_bn.running_var\n",
            "module.base_model.inception_3b_double_3x3_reduce_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_double_3x3_reduce_bn.num_batches_tracked\n",
            "module.base_model.inception_3b_double_3x3_1.weight→eco_2d.inception_b.inception_3b_double_3x3_1.weight\n",
            "module.base_model.inception_3b_double_3x3_1.bias→eco_2d.inception_b.inception_3b_double_3x3_1.bias\n",
            "module.base_model.inception_3b_double_3x3_1_bn.weight→eco_2d.inception_b.inception_3b_double_3x3_1_bn.weight\n",
            "module.base_model.inception_3b_double_3x3_1_bn.bias→eco_2d.inception_b.inception_3b_double_3x3_1_bn.bias\n",
            "module.base_model.inception_3b_double_3x3_1_bn.running_mean→eco_2d.inception_b.inception_3b_double_3x3_1_bn.running_mean\n",
            "module.base_model.inception_3b_double_3x3_1_bn.running_var→eco_2d.inception_b.inception_3b_double_3x3_1_bn.running_var\n",
            "module.base_model.inception_3b_double_3x3_1_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_double_3x3_1_bn.num_batches_tracked\n",
            "module.base_model.inception_3b_double_3x3_2.weight→eco_2d.inception_b.inception_3b_double_3x3_2.weight\n",
            "module.base_model.inception_3b_double_3x3_2.bias→eco_2d.inception_b.inception_3b_double_3x3_2.bias\n",
            "module.base_model.inception_3b_double_3x3_2_bn.weight→eco_2d.inception_b.inception_3b_double_3x3_2_bn.weight\n",
            "module.base_model.inception_3b_double_3x3_2_bn.bias→eco_2d.inception_b.inception_3b_double_3x3_2_bn.bias\n",
            "module.base_model.inception_3b_double_3x3_2_bn.running_mean→eco_2d.inception_b.inception_3b_double_3x3_2_bn.running_mean\n",
            "module.base_model.inception_3b_double_3x3_2_bn.running_var→eco_2d.inception_b.inception_3b_double_3x3_2_bn.running_var\n",
            "module.base_model.inception_3b_double_3x3_2_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_double_3x3_2_bn.num_batches_tracked\n",
            "module.base_model.inception_3b_pool_proj.weight→eco_2d.inception_b.inception_3b_pool_proj.weight\n",
            "module.base_model.inception_3b_pool_proj.bias→eco_2d.inception_b.inception_3b_pool_proj.bias\n",
            "module.base_model.inception_3b_pool_proj_bn.weight→eco_2d.inception_b.inception_3b_pool_proj_bn.weight\n",
            "module.base_model.inception_3b_pool_proj_bn.bias→eco_2d.inception_b.inception_3b_pool_proj_bn.bias\n",
            "module.base_model.inception_3b_pool_proj_bn.running_mean→eco_2d.inception_b.inception_3b_pool_proj_bn.running_mean\n",
            "module.base_model.inception_3b_pool_proj_bn.running_var→eco_2d.inception_b.inception_3b_pool_proj_bn.running_var\n",
            "module.base_model.inception_3b_pool_proj_bn.num_batches_tracked→eco_2d.inception_b.inception_3b_pool_proj_bn.num_batches_tracked\n",
            "module.base_model.inception_3c_double_3x3_reduce.weight→eco_2d.inception_c.inception_3c_double_3x3_reduce.weight\n",
            "module.base_model.inception_3c_double_3x3_reduce.bias→eco_2d.inception_c.inception_3c_double_3x3_reduce.bias\n",
            "module.base_model.inception_3c_double_3x3_reduce_bn.weight→eco_2d.inception_c.inception_3c_double_3x3_reduce_bn.weight\n",
            "module.base_model.inception_3c_double_3x3_reduce_bn.bias→eco_2d.inception_c.inception_3c_double_3x3_reduce_bn.bias\n",
            "module.base_model.inception_3c_double_3x3_reduce_bn.running_mean→eco_2d.inception_c.inception_3c_double_3x3_reduce_bn.running_mean\n",
            "module.base_model.inception_3c_double_3x3_reduce_bn.running_var→eco_2d.inception_c.inception_3c_double_3x3_reduce_bn.running_var\n",
            "module.base_model.inception_3c_double_3x3_reduce_bn.num_batches_tracked→eco_2d.inception_c.inception_3c_double_3x3_reduce_bn.num_batches_tracked\n",
            "module.base_model.inception_3c_double_3x3_1.weight→eco_2d.inception_c.inception_3c_double_3x3_1.weight\n",
            "module.base_model.inception_3c_double_3x3_1.bias→eco_2d.inception_c.inception_3c_double_3x3_1.bias\n",
            "module.base_model.inception_3c_double_3x3_1_bn.weight→eco_2d.inception_c.inception_3c_double_3x3_1_bn.weight\n",
            "module.base_model.inception_3c_double_3x3_1_bn.bias→eco_2d.inception_c.inception_3c_double_3x3_1_bn.bias\n",
            "module.base_model.inception_3c_double_3x3_1_bn.running_mean→eco_2d.inception_c.inception_3c_double_3x3_1_bn.running_mean\n",
            "module.base_model.inception_3c_double_3x3_1_bn.running_var→eco_2d.inception_c.inception_3c_double_3x3_1_bn.running_var\n",
            "module.base_model.inception_3c_double_3x3_1_bn.num_batches_tracked→eco_2d.inception_c.inception_3c_double_3x3_1_bn.num_batches_tracked\n",
            "module.base_model.res3a_2.weight→eco_3d.res_3d_3.res3a_2.weight\n",
            "module.base_model.res3a_2.bias→eco_3d.res_3d_3.res3a_2.bias\n",
            "module.base_model.res3a_bn.weight→eco_3d.res_3d_3.res3a_bn.weight\n",
            "module.base_model.res3a_bn.bias→eco_3d.res_3d_3.res3a_bn.bias\n",
            "module.base_model.res3a_bn.running_mean→eco_3d.res_3d_3.res3a_bn.running_mean\n",
            "module.base_model.res3a_bn.running_var→eco_3d.res_3d_3.res3a_bn.running_var\n",
            "module.base_model.res3a_bn.num_batches_tracked→eco_3d.res_3d_3.res3a_bn.num_batches_tracked\n",
            "module.base_model.res3b_1.weight→eco_3d.res_3d_3.res3b_1.weight\n",
            "module.base_model.res3b_1.bias→eco_3d.res_3d_3.res3b_1.bias\n",
            "module.base_model.res3b_1_bn.weight→eco_3d.res_3d_3.res3b_1_bn.weight\n",
            "module.base_model.res3b_1_bn.bias→eco_3d.res_3d_3.res3b_1_bn.bias\n",
            "module.base_model.res3b_1_bn.running_mean→eco_3d.res_3d_3.res3b_1_bn.running_mean\n",
            "module.base_model.res3b_1_bn.running_var→eco_3d.res_3d_3.res3b_1_bn.running_var\n",
            "module.base_model.res3b_1_bn.num_batches_tracked→eco_3d.res_3d_3.res3b_1_bn.num_batches_tracked\n",
            "module.base_model.res3b_2.weight→eco_3d.res_3d_3.res3b_2.weight\n",
            "module.base_model.res3b_2.bias→eco_3d.res_3d_3.res3b_2.bias\n",
            "module.base_model.res3b_bn.weight→eco_3d.res_3d_3.res3b_bn.weight\n",
            "module.base_model.res3b_bn.bias→eco_3d.res_3d_3.res3b_bn.bias\n",
            "module.base_model.res3b_bn.running_mean→eco_3d.res_3d_3.res3b_bn.running_mean\n",
            "module.base_model.res3b_bn.running_var→eco_3d.res_3d_3.res3b_bn.running_var\n",
            "module.base_model.res3b_bn.num_batches_tracked→eco_3d.res_3d_3.res3b_bn.num_batches_tracked\n",
            "module.base_model.res4a_1.weight→eco_3d.res_3d_4.res4a_1.weight\n",
            "module.base_model.res4a_1.bias→eco_3d.res_3d_4.res4a_1.bias\n",
            "module.base_model.res4a_1_bn.weight→eco_3d.res_3d_4.res4a_1_bn.weight\n",
            "module.base_model.res4a_1_bn.bias→eco_3d.res_3d_4.res4a_1_bn.bias\n",
            "module.base_model.res4a_1_bn.running_mean→eco_3d.res_3d_4.res4a_1_bn.running_mean\n",
            "module.base_model.res4a_1_bn.running_var→eco_3d.res_3d_4.res4a_1_bn.running_var\n",
            "module.base_model.res4a_1_bn.num_batches_tracked→eco_3d.res_3d_4.res4a_1_bn.num_batches_tracked\n",
            "module.base_model.res4a_2.weight→eco_3d.res_3d_4.res4a_2.weight\n",
            "module.base_model.res4a_2.bias→eco_3d.res_3d_4.res4a_2.bias\n",
            "module.base_model.res4a_down.weight→eco_3d.res_3d_4.res4a_down.weight\n",
            "module.base_model.res4a_down.bias→eco_3d.res_3d_4.res4a_down.bias\n",
            "module.base_model.res4a_bn.weight→eco_3d.res_3d_4.res4a_bn.weight\n",
            "module.base_model.res4a_bn.bias→eco_3d.res_3d_4.res4a_bn.bias\n",
            "module.base_model.res4a_bn.running_mean→eco_3d.res_3d_4.res4a_bn.running_mean\n",
            "module.base_model.res4a_bn.running_var→eco_3d.res_3d_4.res4a_bn.running_var\n",
            "module.base_model.res4a_bn.num_batches_tracked→eco_3d.res_3d_4.res4a_bn.num_batches_tracked\n",
            "module.base_model.res4b_1.weight→eco_3d.res_3d_4.res4b_1.weight\n",
            "module.base_model.res4b_1.bias→eco_3d.res_3d_4.res4b_1.bias\n",
            "module.base_model.res4b_1_bn.weight→eco_3d.res_3d_4.res4b_1_bn.weight\n",
            "module.base_model.res4b_1_bn.bias→eco_3d.res_3d_4.res4b_1_bn.bias\n",
            "module.base_model.res4b_1_bn.running_mean→eco_3d.res_3d_4.res4b_1_bn.running_mean\n",
            "module.base_model.res4b_1_bn.running_var→eco_3d.res_3d_4.res4b_1_bn.running_var\n",
            "module.base_model.res4b_1_bn.num_batches_tracked→eco_3d.res_3d_4.res4b_1_bn.num_batches_tracked\n",
            "module.base_model.res4b_2.weight→eco_3d.res_3d_4.res4b_2.weight\n",
            "module.base_model.res4b_2.bias→eco_3d.res_3d_4.res4b_2.bias\n",
            "module.base_model.res4b_bn.weight→eco_3d.res_3d_4.res4b_bn.weight\n",
            "module.base_model.res4b_bn.bias→eco_3d.res_3d_4.res4b_bn.bias\n",
            "module.base_model.res4b_bn.running_mean→eco_3d.res_3d_4.res4b_bn.running_mean\n",
            "module.base_model.res4b_bn.running_var→eco_3d.res_3d_4.res4b_bn.running_var\n",
            "module.base_model.res4b_bn.num_batches_tracked→eco_3d.res_3d_4.res4b_bn.num_batches_tracked\n",
            "module.base_model.res5a_1.weight→eco_3d.res_3d_5.res5a_1.weight\n",
            "module.base_model.res5a_1.bias→eco_3d.res_3d_5.res5a_1.bias\n",
            "module.base_model.res5a_1_bn.weight→eco_3d.res_3d_5.res5a_1_bn.weight\n",
            "module.base_model.res5a_1_bn.bias→eco_3d.res_3d_5.res5a_1_bn.bias\n",
            "module.base_model.res5a_1_bn.running_mean→eco_3d.res_3d_5.res5a_1_bn.running_mean\n",
            "module.base_model.res5a_1_bn.running_var→eco_3d.res_3d_5.res5a_1_bn.running_var\n",
            "module.base_model.res5a_1_bn.num_batches_tracked→eco_3d.res_3d_5.res5a_1_bn.num_batches_tracked\n",
            "module.base_model.res5a_2.weight→eco_3d.res_3d_5.res5a_2.weight\n",
            "module.base_model.res5a_2.bias→eco_3d.res_3d_5.res5a_2.bias\n",
            "module.base_model.res5a_down.weight→eco_3d.res_3d_5.res5a_down.weight\n",
            "module.base_model.res5a_down.bias→eco_3d.res_3d_5.res5a_down.bias\n",
            "module.base_model.res5a_bn.weight→eco_3d.res_3d_5.res5a_bn.weight\n",
            "module.base_model.res5a_bn.bias→eco_3d.res_3d_5.res5a_bn.bias\n",
            "module.base_model.res5a_bn.running_mean→eco_3d.res_3d_5.res5a_bn.running_mean\n",
            "module.base_model.res5a_bn.running_var→eco_3d.res_3d_5.res5a_bn.running_var\n",
            "module.base_model.res5a_bn.num_batches_tracked→eco_3d.res_3d_5.res5a_bn.num_batches_tracked\n",
            "module.base_model.res5b_1.weight→eco_3d.res_3d_5.res5b_1.weight\n",
            "module.base_model.res5b_1.bias→eco_3d.res_3d_5.res5b_1.bias\n",
            "module.base_model.res5b_1_bn.weight→eco_3d.res_3d_5.res5b_1_bn.weight\n",
            "module.base_model.res5b_1_bn.bias→eco_3d.res_3d_5.res5b_1_bn.bias\n",
            "module.base_model.res5b_1_bn.running_mean→eco_3d.res_3d_5.res5b_1_bn.running_mean\n",
            "module.base_model.res5b_1_bn.running_var→eco_3d.res_3d_5.res5b_1_bn.running_var\n",
            "module.base_model.res5b_1_bn.num_batches_tracked→eco_3d.res_3d_5.res5b_1_bn.num_batches_tracked\n",
            "module.base_model.res5b_2.weight→eco_3d.res_3d_5.res5b_2.weight\n",
            "module.base_model.res5b_2.bias→eco_3d.res_3d_5.res5b_2.bias\n",
            "module.base_model.res5b_bn.weight→eco_3d.res_3d_5.res5b_bn.weight\n",
            "module.base_model.res5b_bn.bias→eco_3d.res_3d_5.res5b_bn.bias\n",
            "module.base_model.res5b_bn.running_mean→eco_3d.res_3d_5.res5b_bn.running_mean\n",
            "module.base_model.res5b_bn.running_var→eco_3d.res_3d_5.res5b_bn.running_var\n",
            "module.base_model.res5b_bn.num_batches_tracked→eco_3d.res_3d_5.res5b_bn.num_batches_tracked\n",
            "module.new_fc.weight→fc_final.weight\n",
            "module.new_fc.bias→fc_final.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o749GlU2Cn9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99015ba7-5762-4290-c16e-35863d8e419d"
      },
      "source": [
        "net.eval()  # ECOネットワークを推論モードに\n",
        "\n",
        "batch_iterator = iter(val_dataloader)  # イテレータに変換\n",
        "imgs_transformeds, labels, label_ids, dir_path = next(\n",
        "    batch_iterator)  # 1番目の要素を取り出す\n",
        "\n",
        "with torch.set_grad_enabled(False):\n",
        "    outputs = net(imgs_transformeds)  # ECOで推論\n",
        "\n",
        "print(outputs.shape)  # 出力のサイズ"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 400])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNHmgDxJCqPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0ceaebc7-b8c7-40a4-abff-09c43db5b65c"
      },
      "source": [
        "def show_eco_inference_result(dir_path, outputs_input, id_label_dict, idx=0):\n",
        "    '''ミニバッチの各データに対して、推論結果の上位を出力する関数を定義'''\n",
        "    print(\"ファイル：\", dir_path[idx])  # ファイル名\n",
        "\n",
        "    outputs = outputs_input.clone()  # コピーを作成\n",
        "\n",
        "    for i in range(5):\n",
        "        '''1位から5位までを表示'''\n",
        "        output = outputs[idx]\n",
        "        _, pred = torch.max(output, dim=0)  # 確率最大値のラベルを予測\n",
        "        class_idx = int(pred.numpy())  # クラスIDを出力\n",
        "        print(\"予測第{}位：{}\".format(i+1, id_label_dict[class_idx]))\n",
        "        outputs[idx][class_idx] = -1000  # 最大値だったものを消す（小さくする）\n",
        "\n",
        "\n",
        "# 予測を実施\n",
        "idx = 0\n",
        "show_eco_inference_result(dir_path, outputs, id_label_dict, idx)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ファイル： ./data/kinetics_videos/bungee jumping/dAeUFSdYG1I_000010_000020\n",
            "予測第1位：bungee jumping\n",
            "予測第2位：snowkiting\n",
            "予測第3位：kitesurfing\n",
            "予測第4位：parasailing\n",
            "予測第5位：swinging on something\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0gzwJzrCtQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "da26a16b-fdc7-41cb-89a4-3786c1a0c161"
      },
      "source": [
        "idx = 4\n",
        "show_eco_inference_result(dir_path, outputs, id_label_dict, idx)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ファイル： ./data/kinetics_videos/arm wrestling/5JzkrOVhPOw_000027_000037\n",
            "予測第1位：arm wrestling\n",
            "予測第2位：stretching leg\n",
            "予測第3位：headbutting\n",
            "予測第4位：shaking hands\n",
            "予測第5位：massaging feet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0G8KL480lxP",
        "colab_type": "text"
      },
      "source": [
        "以上"
      ]
    }
  ]
}